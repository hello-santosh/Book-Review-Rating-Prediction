{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "df_train = pd.read_csv('goodreads_train.csv')\n",
    "df_test = pd.read_csv('goodreads_test.csv')\n",
    "df_sub = pd.read_csv('goodreads_sample_submission.csv')\n",
    "\n",
    "# Delete dublicate reviews and review_id\n",
    "df_train.drop_duplicates(subset=[\"review_id\"], inplace=True, keep='first')\n",
    "df_train.drop_duplicates(subset=[\"review_text\"], inplace=True, keep='first')\n",
    "\n",
    "# Delete reviews with less than 5 letters.\n",
    "indexReviewText = df_train.loc[ df_train['review_text'].str.len() <= 5].index\n",
    "df_train.drop(indexReviewText , inplace=True)\n",
    "\n",
    "# # Delete needless columns\n",
    "df_train.drop(columns=['book_id','review_text','n_votes','n_comments','user_id','date_added','date_updated','read_at','started_at'])\n",
    "\n",
    "# Clean the review data which consists of word greater than 30\n",
    "get_word_length = lambda phrase: np.mean(list(map(len, phrase.split())))\n",
    "condition = df_train.review_text.apply(get_word_length) > 30\n",
    "index = df_train.index\n",
    "bad_word_indices = index[condition].tolist()\n",
    "df_train.drop(bad_word_indices,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87258e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rating'].value_counts()\n",
    "df_train = df_train.groupby('rating').head(28555)\n",
    "condition = df_train.review_text.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d7048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_linear_regression(input_feature, output):\n",
    "    count = len(input_feature)\n",
    "    numerator = ((input_feature*output).sum()) - ((1/count)*(input_feature.sum()*output.sum()))\n",
    "    denominator = (input_feature*input_feature).sum() - (1/count)*(input_feature.sum()*input_feature.sum())\n",
    "    slope = numerator/denominator\n",
    "    intercept = output.mean() - (slope *(input_feature.mean()))\n",
    "    return (intercept, slope)\n",
    "\n",
    "intercept, slope = simple_linear_regression(condition, df_train['rating'])\n",
    "\n",
    "def get_regression_predictions(input_feature, intercept, slope):\n",
    "    predicted_values = intercept + slope*input_feature\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_rating = []\n",
    "\n",
    "for reviews in df_test['review_text']:\n",
    "    rating = get_regression_predictions(len(reviews), intercept, slope)\n",
    "    estimated_rating.append(round(rating))\n",
    "    \n",
    "df_sub.rating = estimated_rating\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
